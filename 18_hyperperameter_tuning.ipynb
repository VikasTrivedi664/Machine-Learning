{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter Tuning\n",
    "\n",
    "The idea is to assign the train and test split to a RandomForestClassifier object and specify the list of parameters and distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the data\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # define the model\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # create the perameter grid\n",
    "\n",
    "# param_grid = { \n",
    "#     'n_estimators': [50,100,200,300,400,500,],\n",
    "#     'max_depth':[4,5,6,7,8,9,10],\n",
    "#     'creterion':['gini','entropy'],\n",
    "#     'bootstrap':[True,False],\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "# print the best score and the best perameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up the grid\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring = 'Accuracy',\n",
    "#     verbose = 1,\n",
    "#     n_jobs = -1,\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter Tuning\n",
    "\n",
    "Hyperperameter tuning is the process of finding  the optimal set of hyperparameters for a given machine learning model. This can be done using various techniques.\n",
    "\n",
    "--Types--\n",
    "\n",
    "1. Grid Search \n",
    "2. Random Search\n",
    "3. Bayesian Optimization\n",
    "4. Gradient Based Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation \n",
    "\n",
    "Cross-validation is a technique used in machine learning to assess the performance and generalization ability of a model. It involves dividing the dataset into multiple folds, where each fold is used as a validation set while the remaining folds are used for training the model. This process is repeated for each fold, and the average performance across all folds is calculated to obtain a more robust estimate of the model's performance.\n",
    "\n",
    "There are several types of cross-validation techniques, including:\n",
    "\n",
    "1. k-fold cross-validation:\n",
    " The dataset is divided into k equal-sized folds, and the model is trained and validated k times, where each fold is used as the validation set once. The average performance across all k folds is used as the estimate of the model's performance.\n",
    "2. Stratified k-fold cross-validation:\n",
    " Similar to k-fold cross-validation, but the folds are chosen such that each fold contains roughly the same percentage of samples of each target class as the complete dataset. This is useful for imbalanced datasets where some classes may be underrepresented in the dataset.\n",
    "3. Leave-one-out cross-validation:\n",
    " A special case of k-fold cross-validation where k is equal to the number of samples in the dataset. In each iteration, one sample is left out as the validation set, and the remaining samples are used for training the model.\n",
    " \n",
    "4. Time series cross-validation:\n",
    " A special case of cross-validation for time series data, where the dataset is divided into training and validation sets based on time. The model is trained on the past observations and validated on the future observations.\n",
    "Cross-validation helps to prevent overfitting by providing a more robust estimate of the model's performance on unseen data. It also helps to identify the best hyperparameters for the model by evaluating the model's performance with different hyperparameters on different folds of the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the data\n",
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "# model = GridSearchCV()\n",
    "\n",
    "# # define the grid\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_depth': [4,5,6,7,8,9,10],\n",
    "#     'max_features':['auto','sqrt','log2'],\n",
    "#     'criterion':['gini','entropy']\n",
    "# }\n",
    "\n",
    "# # set up the grid\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1,\n",
    "#                     scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# grid.fit(X, y)\n",
    "\n",
    "# # print the best parameters\n",
    "# print('Best Parameters',grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomizedSearchCV.__init__() missing 2 required positional arguments: 'estimator' and 'param_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomizedSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# define the grid\u001b[39;00m\n\u001b[0;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m }\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomizedSearchCV.__init__() missing 2 required positional arguments: 'estimator' and 'param_distributions'"
     ]
    }
   ],
   "source": [
    "model = RandomizedSearchCV()\n",
    "\n",
    "# define the grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [4,5,6,7,8,9,10],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "\n",
    "# set up the grid\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=5, n_iter=20, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y)\n",
    "\n",
    "# print the best parameters\n",
    "print('Best Parameters',grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
