{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Based Algorithm\n",
    "\n",
    "Naive Bayes is a family of generative machine learning algorithms used for classification tasks. It is based on Bayes' Theorem and assumes conditional independence of predictors. Despite this unrealistic assumption, Naive Bayes classifiers perform well, particularly with small sample sizes.\n",
    "\n",
    "There are different types of Naive Bayes classifiers, including Gaussian, Multinomial, and Bernoulli, which differ based on the distributions of the feature values.\n",
    "\n",
    "In Naive Bayes, the class-conditional probabilities and the prior probabilities are calculated to yield the posterior probabilities. The classifier then returns the class with the maximum posterior probability out of a group of classes for a given input.\n",
    "\n",
    "To evaluate the performance of a Naive Bayes classifier, a confusion matrix can be plotted, which shows the actual and predicted values within a matrix.\n",
    "\n",
    "Naive Bayes is commonly used in text classification, spam filtering, and recommendation systems. It is also used in other applications such as image classification and natural language processing.\n",
    "\n",
    "Some advantages of Naive Bayes include its simplicity, scalability, and robustness to irrelevant features. However, it may perform poorly when the assumption of conditional independence is violated.\n",
    "\n",
    "In summary, Naive Bayes is a powerful and versatile classification algorithm that is widely used in machine learning and data mining applications.\n",
    "\n",
    "# Bayes Theorem\n",
    "Bayes' Theorem is a fundamental concept in probability theory and statistics. It is named after the English mathematician Thomas Bayes. It is used to calculate the conditional probability of an event, given the probability of another event.\n",
    "\n",
    "Bayes' Theorem states that the conditional probability of two events, A and B, is equal to the product of the probability of B given A, and the probability of A, divided by the probability of B. Mathematically, it can be represented as:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "Here, P(A|B) is the probability of event A occurring, given that event B has occurred. P(B|A) is the probability of event B occurring, given that event A has occurred. P(A) and P(B) are the probabilities of events A and B, respectively.\n",
    "\n",
    "Bayes' Theorem is used in various fields, including machine learning, statistics, and decision theory. It is the foundation of the Naive Bayes classifier, which is a popular algorithm used for classification tasks.\n",
    "\n",
    "In machine learning, Bayes' Theorem is used to calculate the posterior probabilities of the classes given the input features. The classifier then selects the class with the highest posterior probability as the prediction.\n",
    "\n",
    "In summary, Bayes' Theorem is a fundamental concept in probability theory and statistics that is used to calculate the conditional probability of two events. It is widely used in machine learning and other fields to make predictions and decisions based on data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import  GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split the data\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9777777777777777\n",
      "confusion_matrix [[19  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  1 13]]\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "print('accuracy_score',accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix',confusion_matrix(y_pred,y_test))\n",
    "print('classification_report',classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9777777777777777\n",
      "confusion_matrix [[19  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  1 13]]\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "# train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "print('accuracy_score',accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix',confusion_matrix(y_pred,y_test))\n",
    "print('classification_report',classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9777777777777777\n",
      "confusion_matrix [[19  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  1 13]]\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "# train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "print('accuracy_score',accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix',confusion_matrix(y_pred,y_test))\n",
    "print('classification_report',classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
